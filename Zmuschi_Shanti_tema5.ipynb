{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zmuschi_Shanti_tema5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPY4+UfALnElz71bdMOzQkT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szmuschi/RN/blob/main/Zmuschi_Shanti_tema5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oyYhAAn2RXu_"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz71IGdGRgl7",
        "outputId": "5fb287e7-4ba5-46f7-9b54-24d6c21e4771"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "metadata": {
        "id": "lgpmAezmSIvw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlnniMTRSZUy",
        "outputId": "d61779cc-b74a-47a9-803c-7a9907b0c8bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 500, 32)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               53200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 350)               35350     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 350)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 351       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 248,901\n",
            "Trainable params: 248,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='rmsprop', \n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "89wyKqlqSeMY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhrPgPpYShN2",
        "outputId": "479b10c1-9230-4ea6-f091-77bbeb6174a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 272s 684ms/step - loss: 0.4800 - accuracy: 0.7735 - val_loss: 0.3273 - val_accuracy: 0.8622\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 266s 681ms/step - loss: 0.3237 - accuracy: 0.8694 - val_loss: 0.3101 - val_accuracy: 0.8700\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 265s 679ms/step - loss: 0.2779 - accuracy: 0.8916 - val_loss: 0.2998 - val_accuracy: 0.8773\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa21e71aed0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdSSpB2YSobw",
        "outputId": "eb23fb10-96b6-4f78-ceda-4c83dc1c56b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8772799968719482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "2aqIRrxJcFb6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"model.h5\")\n",
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "batch_size = 256\n",
        "num_epochs = 1\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3MVkz-icuUj",
        "outputId": "1d0aa7cb-bb41-4e7d-d3c0-6e2dad0ab277"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 242s 2s/step - loss: 0.2130 - accuracy: 0.9187 - val_loss: 0.2802 - val_accuracy: 0.8826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa2242c9250>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "mqIyNLdixAfk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"model.h5\")\n",
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "batch_size = 256\n",
        "num_epochs = 1\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tW5lUqAw87U",
        "outputId": "49885537-894c-4ca0-dc62-f80996adbc9f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 243s 2s/step - loss: 0.1908 - accuracy: 0.9283 - val_loss: 0.2838 - val_accuracy: 0.8850\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa222b4b910>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "7BkvRwSZjYNj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import load_model\n",
        "import sys\n",
        "\n",
        "#numarul maxim de cuvinte pe care vreti sa le considerati\n",
        "nr_cuv_diferite = 5000 #ex: 5000\n",
        "#dimensiunea maxima a unui review\n",
        "dim_max = 500 #ex: 500\n",
        "if __name__ == '__main__':\n",
        "  # Load the dataset\n",
        "  (X_train, Y_train), (X_test, Y_test) = imdb.load_data(num_words = nr_cuv_diferite)\n",
        "  model = load_model(\"model.h5\")\n",
        "  X_test = sequence.pad_sequences(X_test, maxlen=dim_max)\n",
        "  scores = model.evaluate(X_test, Y_test)\n",
        "  model.summary()\n",
        "  print('Loss: %.3f' % scores[0])\n",
        "  print('Accuracy: %.3f' % scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62y0_N4YRunD",
        "outputId": "6b565ff8-4105-4021-8d94-3f1d3011d24b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 68s 86ms/step - loss: 0.2838 - accuracy: 0.8850\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 500, 32)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               53200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 350)               35350     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 350)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 351       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 248,901\n",
            "Trainable params: 248,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Loss: 0.284\n",
            "Accuracy: 0.885\n"
          ]
        }
      ]
    }
  ]
}